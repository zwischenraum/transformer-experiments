run:
  project: transformer
  name: train
  artifact:
    filename: checkpoint.pt
    name: model-checkpoint

training:
  total_steps: 10
  batch_size: 30
  learning_rate: 0.0001
  seq_len: 1024

model:
  d_model: 512
  n_heads: 8
  n_layers: 6
  d_ff: 2048
  dropout: 0.1

dataset:
  path: HuggingFaceFW/fineweb-edu
  name: sample-10BT
  split: train
  streaming: true
  tokenizer: openai-community/gpt2

  tokenizer_batch_size: 50
  shuffle:
    seed: 42
    buffer_size: 10000
